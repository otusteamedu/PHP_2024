# Логи будут прилетать из beats'ов по порту 5044
input {
  beats {
    port => 5044
  }
}

filter {
  # Дропаем лог, если он пришел от неизвестного нам сервиса (по желанию)
  # Ниже я два раза указал host_metrics_app в списке - это не опечатка. Какого-то лешего в условии, в массиве должно быть минимум 2 элемента.
  # Так как приложение у нас одно - просто дублируем
  # Поле service у нас появится благодаря конфигурированию Filebeat
  if [fields][service] not in ["host_metrics_app", "host_metrics_app"] {
    drop {}
  }
  # Оригинальный json-лог, который был сгенерирован вашим приложением, будет лежать по ключу message
  # (из filebeat'а логи прилетают не в чистом виде)
  json {
    source => "message"
  }
  # Говорим logstash'у, чтобы в качестве timestamp'а лога он брал именно наш timestamp
  # (в моем случае поле asctime в теле сообщения в формате "yyyy-MM-dd HH:mm:ss.SSS" и часовом поясе UTC)
  # и затем подтирал поле asctime.
  date {
    match => ["asctime", "yyyy-MM-dd HH:mm:ss.SSS"]
    timezone => "UTC"
    target => "@timestamp"
    remove_field => ["asctime"]
  }
}

output {
  # Отображаем лог в stdout (поиграйтесь и удалите данную строку)
  stdout {}
  # Пушим лог в elasticsearch, индекс будет создан автоматически по названию сервиса и текущей дате
  elasticsearch {
    hosts => "elasticsearch:9200"
    index => "logs_%{[fields][service]}-%{+YYYY.MM.dd}"
    user => "elastic"
    password => "MyPw123"
  }
}